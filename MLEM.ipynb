{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLEM Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this notebook, you need the [Operator Discretization Library (ODL)](https://github.com/odlgroup/odl), which itself depends on the [Astra toolbox](https://github.com/astra-toolbox/astra-toolbox). You also need the plotting library [Holoviews](http://holoviews.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import odl\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some general plotting functions to compute `odl` images with `holoviews`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "import xarray as xr\n",
    "\n",
    "def coords_from_space(space):\n",
    "    coords = [axis.points().squeeze(axis=-1) for axis in space.partition.byaxis]\n",
    "    return coords\n",
    "\n",
    "def sanitize_label(axis_label):\n",
    "    \"\"\"\n",
    "    This function only exists to remove dollar signs.\n",
    "    \"\"\"\n",
    "    sanitized = axis_label.replace('$', '').replace(r\"\\varphi\", 'φ')\n",
    "    return sanitized\n",
    "\n",
    "def sanitize_labels(axis_labels):\n",
    "    return [sanitize_label(label) for label in axis_labels]\n",
    "\n",
    "def xarray_from_element(element):\n",
    "    coords = coords_from_space(element.space)\n",
    "    xarr = xr.DataArray(element, coords=coords, dims=sanitize_labels(element.space.axis_labels), name='Intensity')\n",
    "    return xarr\n",
    "\n",
    "def show_image(element):\n",
    "    xarr = xarray_from_element(element)\n",
    "    im = hv.Image(xarr)\n",
    "    im.opts(cmap='bone')\n",
    "    return im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The forward operator that we will use for the experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for getting a CT operator which given image resolution\n",
    "def get_ray_trafo(resolution=256):\n",
    "    \"\"\"\n",
    "    Gives full size ray transform.\n",
    "    The data space seems too big in practice.\n",
    "    \"\"\"\n",
    "    reco_space = odl.uniform_discr(\n",
    "        min_pt=[-20, -20], max_pt=[20, 20], shape=[resolution, resolution], dtype='float32')\n",
    "\n",
    "    # Make a parallel beam geometry with flat detector\n",
    "    angle_partition = odl.uniform_partition(0, np.pi, 90)\n",
    "\n",
    "    # Detector: uniformly sampled, n = 512, min = -30, max = 30\n",
    "    detector_partition = odl.uniform_partition(-20, 20, 128)\n",
    "\n",
    "    geometry = odl.tomo.Parallel2dGeometry(angle_partition, detector_partition)\n",
    "\n",
    "    # Ray transform (= forward projection).\n",
    "    ray_trafo = odl.tomo.RayTransform(reco_space, geometry)\n",
    "    return ray_trafo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primal function (divergence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non normalised divergence between two nonnegative vectors $u$ and $v$ is\n",
    "\\\\[\n",
    "δ(u||v) = \\sum_i v_i - u_i + u_i \\log(u_i/v_i)\n",
    "\\\\]\n",
    "It is related to the standard divergence by\n",
    "\\\\[\n",
    "δ(u||v) = M(u) \\Bigl[ f - 1 - \\log (f) + D(\\bar{u}||\\bar{v}) \\Bigr] \\qquad f := \\frac{M(v)}{M(u)}\n",
    "\\\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divergence(x,y):\n",
    "    xlogy = scipy.special.xlogy(x, x) - scipy.special.xlogy(x, y)\n",
    "    Mx = np.sum(x)\n",
    "    res = np.sum(y - x + xlogy)\n",
    "    if not np.all(np.isfinite(res)):\n",
    "        print(scipy.special.xlogy(x, y))\n",
    "    return res/Mx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLEM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A careful implementation of the MLEM algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xovery(x, y, eps=1e-50):\n",
    "    mask = np.abs(x) > eps\n",
    "    res = np.zeros_like(x)\n",
    "    res[mask] = x[mask] / y[mask]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mlem(op, x, data, niter=1000, eps=1e-20):\n",
    "    sensitivity = op.adjoint(op.range.one())\n",
    "    for i in tqdm(range(niter)):\n",
    "        #x_ = (x/sensitivity)*op.adjoint((data/np.maximum(op(x),eps)))\n",
    "        y = op(x)\n",
    "        yield (x,y)\n",
    "        x_ = (x/sensitivity)*op.adjoint(xovery(data.asarray(),y.asarray(), eps))\n",
    "        x = x_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phantom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some phantoms for the experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = get_ray_trafo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torus(x):\n",
    "    r2 = x[0]**2 + x[1]**2\n",
    "    r = np.sqrt(r2)\n",
    "    return np.exp(-(r-15)**2) + 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phantom = op.domain.element(torus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.Image(xarray_from_element(phantom)).opts(hv.opts.Image(colorbar=True, width=400))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeRenzo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phantom = odl.phantom.emission.derenzo_sources(op.domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.Image(xarray_from_element(phantom)).opts(hv.opts.Image(colorbar=True, width=400))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data (sinogram)\n",
    "data = op(phantom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noisy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noisy_data(data, level):\n",
    "    alpha = level*odl.phantom.noise.poisson_noise(data/level)\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File saving utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some auxilliary functions to save the resulting figures in relevant subfolders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_destination_template(level, data_dir_name='mlem_data'):\n",
    "    formatted_level = '{:.1e}'.format(level)\n",
    "    data_dir = Path() / data_dir_name\n",
    "    data_dir.mkdir(exist_ok=True)\n",
    "    dir_destination = data_dir / 'level_{}'.format(formatted_level)\n",
    "    print(dir_destination)\n",
    "    dir_destination.mkdir(exist_ok=True)\n",
    "    data_destination = dir_destination / '{}.{}'\n",
    "    return data_destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_curve(curve, fname):\n",
    "    hv.save(curve.opts(toolbar=None), backend='bokeh', filename=fname, fmt='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_fig(func, reco, fname):\n",
    "    fig, ax = plt.subplots()\n",
    "    func(reco, ax)\n",
    "    ax.set_aspect(1)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(fname, dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(alpha, niter=2**8):\n",
    "    rs = list(generate_mlem(op, op.domain.one(), alpha, niter=niter))\n",
    "    recos, ys = list(zip(*rs))\n",
    "    return recos, ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divergences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The divergence to data figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_div_curve(alpha, ys):\n",
    "    divs = np.array([divergence(alpha, y) for y in ys[1:]])\n",
    "    print ('{:.2e}'.format(divs[-1]))\n",
    "    div_curve = hv.Curve(divs).redim.label(x='k', y='divergence to data').opts(hv.opts.Curve(width=250, height=200)).opts(hv.opts.Curve(ylim=(0,None), line_width=4, show_grid=True)) * hv.HLine(divs[-1]).opts(hv.opts.HLine(alpha=.3, color='Black'))\n",
    "    return div_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 95% percentile figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quantile_curve(recos):\n",
    "    quantiles = np.array([np.quantile(reco, .95) for reco in recos])\n",
    "    quant_curve = hv.Curve(quantiles[1:]).opts(hv.opts.Curve(logy=True, line_width=4, show_grid=True)).redim.label(x='k', y='95% percentile')\n",
    "    quant_curve.opts(width=250, height=200)\n",
    "    return quant_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A smoothed out version of the reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorcet as cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_filter_img(reco, ax, sigma=3):\n",
    "    filtered = op.domain.element(sp.ndimage.filters.gaussian_filter(reco, sigma=sigma))\n",
    "    xarray_from_element(filtered).T.plot(cmap=cc.cm.gray, ax=ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With clim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A limited dynamic range version of the reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clim_img(reco, ax):\n",
    "    xarray_from_element(reco).T.plot(cmap=cc.cm.gray, vmax=1, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dual certificates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute dual certificates which make sure that the minimum is strictly positive. This means that the noisy data is outside the image of the oeprator, and therefore entails sparsity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we need dual feasibility for $\\lambda$, i.e., $A^T\\lambda \\geq 0$, add small constant to $\\lambda$ to get a dual feasible variable. \n",
    "\n",
    "The choice scaling = 1 below ensures $A^T\\lambda \\geq 0$, but start from scaling = 0.5 which can be enough, if not, increase it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dual(alpha, dual):\n",
    "    if np.min(op.adjoint(dual)) < 0:\n",
    "        raise ValueError(\"Unfeasible variable, increase scaling\")\n",
    "    return np.sum(scipy.special.xlogy(alpha, 1-dual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def certify(reco, alpha, scaling=.5):\n",
    "    # Compute candidate for dual certificate\n",
    "    lamda = (op.range.one()-xovery(alpha.asarray(),op(recos[-1]).asarray())).asarray()\n",
    "\n",
    "    np.min(op.adjoint(lamda)/np.sqrt(np.sum(lamda**2)));\n",
    "    sparsity = op.adjoint(lamda);\n",
    "    mini = np.min(sparsity)\n",
    "    mini2 = np.min(op.adjoint(op.range.one()))\n",
    "    lamda_modified = lamda - scaling*(mini/mini2)\n",
    "\n",
    "    # Certification: if not dual feasible, increase scaling above. \n",
    "    # When dual feasibility is achieved, without certification, try and increase number of ML-EM iterations\n",
    "    d = dual(alpha, lamda_modified)\n",
    "        \n",
    "    if d > 0: \n",
    "        return True\n",
    "    else:\n",
    "        raise ValueError(\"bad luck, this is not a dual certificate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows to generate all the relevant figures in one function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_all(level):\n",
    "    destination_template = get_destination_template(level)\n",
    "\n",
    "    np.random.seed(10)\n",
    "\n",
    "    alpha = get_noisy_data(data, level)\n",
    "\n",
    "    recos, ys = run(alpha)\n",
    "\n",
    "    div_curve = get_div_curve(alpha, ys)\n",
    "\n",
    "    save_curve(div_curve, fname=destination_template.as_posix().format('div', 'png'))\n",
    "\n",
    "    quant_curve = get_quantile_curve(recos)\n",
    "\n",
    "    save_curve(quant_curve, fname=destination_template.as_posix().format('quant', 'png'))\n",
    "\n",
    "    save_fig(plot_filter_img, recos[-1], fname=destination_template.as_posix().format('smooth', 'png'))\n",
    "\n",
    "    save_fig(plot_clim_img, recos[-1], fname=destination_template.as_posix().format('clim', 'png'))\n",
    "    \n",
    "    return alpha, recos, ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we generate all the figures for various noise levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for level in [10**int(k) for k in np.arange(-2,3)]:\n",
    "    alpha, recos, ys = save_all(level)\n",
    "    try:\n",
    "        c = certify(recos[-1], alpha=alpha, scaling=1)\n",
    "        if c:\n",
    "            print(\"Sparsity is certified!\")\n",
    "    except ValueError as ve:\n",
    "        print(ve)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha, recos, ys = save_all(level=1e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_div_curve(alpha, ys)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
